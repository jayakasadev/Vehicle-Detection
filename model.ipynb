{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries are loaded.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from itertools import chain\n",
    "import decimal\n",
    "\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import time\n",
    "\n",
    "# from os import path\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"All libraries are loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL\n",
    "I'm going to load the training samples with which I will train the classifier. These example images come from a combination of the GTI vehicle image database, the KITTI vision benchmark suite, and examples extracted from the project video itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8792\n",
      "<class 'str'>\n",
      "8968\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "path_to_vehicles = \"./dataset/vehicles/\"\n",
    "path_to_nonvehicles = \"./dataset/non-vehicles/\"\n",
    "\n",
    "\"\"\"\n",
    "This method is for when I want to load all image file paths into memory\n",
    "\"\"\"\n",
    "def file_list(path):\n",
    "    return [y for x in os.walk(path) for y in glob(os.path.join(x[0], '*.png'))]\n",
    "\n",
    "\"\"\"\n",
    "This method is for when I want to get a generator of all image file paths \n",
    "\"\"\"\n",
    "def file_generator(path):\n",
    "    return (chain.from_iterable(glob(os.path.join(x[0], '*.png')) for x in os.walk('.')))\n",
    "\n",
    "vehicles = file_list(path_to_vehicles)\n",
    "non_vehicles = file_list(path_to_nonvehicles)\n",
    "\n",
    "print(len(vehicles))\n",
    "print(type(vehicles[0]))\n",
    "print(len(non_vehicles))\n",
    "print(type(non_vehicles[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters used in the phase of feature extraction\n",
    "feat_extraction_params = {'color_space': 'RGB',       # Can be RGB, HSV, LUV, HLS, YUV, YCrCb, BGR\n",
    "                          'orient': 9,                # HOG orientations\n",
    "                          'pix_per_cell': 8,          # HOG pixels per cell\n",
    "                          'cell_per_block': 2,        # HOG cells per block\n",
    "                          'spatial_size': (32, 32),   # Spatial binning dimensions\n",
    "                          'nbins': 16,            # Number of histogram bins\n",
    "                          'hog_channel': \"ALL\",       # Can be 0, 1, 2, or \"ALL\"\n",
    "                          'spatial_feat': True,       # Spatial features on or off\n",
    "                          'hist_feat': True,          # Histogram features on or off\n",
    "                          'hog_feat': True,           # HOG features on or off\n",
    "                          'feature_vec' : True ,       # Call ravel() automatically or not,\n",
    "                          'transform_sqrt': False,     # Turn \"gamma\" normalization on or off\n",
    "                          'visualize': False}          # Turn on visualization or off "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_color(img, conv='YCrCb'):\n",
    "    if conv == 'YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    if conv == 'RGB':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if conv == 'LUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2LUV)\n",
    "    if conv == 'HSV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    if conv == 'HLS':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    if conv == 'YUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2YUV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True, transform_sqrt = False):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=transform_sqrt, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt=transform_sqrt, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_spatial(img, size=(32, 32)):\n",
    "    color1 = cv2.resize(img[:,:,0], size).ravel()\n",
    "    color2 = cv2.resize(img[:,:,1], size).ravel()\n",
    "    color3 = cv2.resize(img[:,:,2], size).ravel()\n",
    "    return np.hstack((color1, color2, color3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color_hist(img, nbins=32):    #bins_range=(0, 256)\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Consider using multiple threads here to speed this process up\n",
    "def load_features(image):\n",
    "    # loading dictionary values\n",
    "    color_space = feat_extraction_params['color_space']\n",
    "    \n",
    "    orient = feat_extraction_params['orient']\n",
    "    pix_per_cell = feat_extraction_params['pix_per_cell']\n",
    "    cell_per_block = feat_extraction_params['cell_per_block']\n",
    "    spatial_size = feat_extraction_params['spatial_size']\n",
    "    nbins = feat_extraction_params['nbins']\n",
    "    \n",
    "    hog_channel = feat_extraction_params['hog_channel']\n",
    "    \n",
    "    feature_vec = feat_extraction_params['feature_vec']\n",
    "    transform_sqrt = feat_extraction_params['transform_sqrt']\n",
    "    visualize = feat_extraction_params['visualize']\n",
    "    \n",
    "    spatial_feat = feat_extraction_params['spatial_feat']\n",
    "    hist_feat = feat_extraction_params['hist_feat']\n",
    "    hog_feat = feat_extraction_params['hog_feat']\n",
    "    \n",
    "    \n",
    "    #1) Define an empty list to receive features\n",
    "    features = []\n",
    "    \n",
    "    #2) Apply color conversion if other than 'RGB'\n",
    "    if color_space != 'BGR':\n",
    "        img = convert_color(image, conv=color_space)\n",
    "    else: \n",
    "        feature_image = np.copy(img)      \n",
    "    \n",
    "    #3) Compute spatial features if flag is set\n",
    "    if spatial_feat == True:\n",
    "        spatial_features = bin_spatial(img, size=spatial_size)\n",
    "        \n",
    "        #4) Append features to list\n",
    "        features.append(spatial_features)\n",
    "    \n",
    "    #5) Compute histogram features if flag is set\n",
    "    if hist_feat == True:\n",
    "        hist_features = color_hist(img, nbins=nbins)\n",
    "        \n",
    "        #6) Append features to list\n",
    "        features.append(hist_features)\n",
    "    \n",
    "    #7) Compute HOG features if flag is set\n",
    "    if hog_feat == True:\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(img.shape[2]):\n",
    "                hog_features.extend(get_hog_features(img[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))      \n",
    "        else:\n",
    "            hog_features = get_hog_features(img[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        #8) Append features to list\n",
    "        features.append(hog_features)\n",
    "\n",
    "    #9) Return concatenated array of features\n",
    "    return np.concatenate(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_extraction(file_list):\n",
    "    \n",
    "    # features will be stores in a list\n",
    "    features = []\n",
    "    \n",
    "    for file in file_list:\n",
    "        # print(file)\n",
    "        img = cv2.imread(file)\n",
    "        \n",
    "        features.append(load_features(img))\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xfilename = \"./variables/X_values.npy\"\n",
    "yfilename = \"./variables/y_values.npy\"\n",
    "loaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vehicles processing took 69.50460433959961 seconds.\n",
      "Non-Vehicles processing took 70.44974565505981 seconds.\n"
     ]
    }
   ],
   "source": [
    "if ((os.path.isfile(Xfilename) != True) and (os.path.isfile(yfilename) != True)): \n",
    "    # reassigning the vehicles and non_vehicles variable because I no longer need the paths to the images\n",
    "    # better to free that memory up\n",
    "    t1 = time.time()\n",
    "    vehicles = feature_extraction(vehicles)\n",
    "    t2 = time.time()\n",
    "    print(\"Vehicles processing took\", (t2-t1), \"seconds.\")\n",
    "    t3 = time.time()\n",
    "    non_vehicles = feature_extraction(non_vehicles)\n",
    "    t4 = time.time()\n",
    "    print(\"Non-Vehicles processing took\", (t4-t3), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "8792\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(8412,)\n",
      "(8412,)\n"
     ]
    }
   ],
   "source": [
    "print(type(vehicles))\n",
    "print(len(vehicles))\n",
    "print(type(non_vehicles))\n",
    "print(type(vehicles[0]))\n",
    "print(type(non_vehicles[0]))\n",
    "print(vehicles[0].shape)\n",
    "print(non_vehicles[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150.0\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "print(non_vehicles[0][0])\n",
    "print(type(non_vehicles[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from images\n",
      "(17760, 8412)\n",
      "(17760,)\n"
     ]
    }
   ],
   "source": [
    "if ((os.path.isfile(Xfilename) != True) and (os.path.isfile(yfilename) != True)):\n",
    "    print(\"loading from images\")\n",
    "    tup = (vehicles, non_vehicles)\n",
    "    X = np.vstack(tup)\n",
    "    # X = np.array(X, dtype = np.float64)                        \n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    # Apply the scaler to X\n",
    "    X = X_scaler.transform(X)\n",
    "\n",
    "    # Define the labels vector\n",
    "    y = np.hstack((np.ones(len(vehicles)), np.zeros(len(non_vehicles))))\n",
    "\n",
    "\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "else:\n",
    "    print(\"Loading from file...\")\n",
    "    y = np.load(yfilename)\n",
    "    print(\"Finished loading y!\")\n",
    "    X = np.load(Xfilename)\n",
    "    print(\"Finished loading X!\")\n",
    "    loaded = True\n",
    "    print(X.shape)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X and y saved.\n",
      "(17760, 8412)\n",
      "(17760,)\n"
     ]
    }
   ],
   "source": [
    "if loaded != True:\n",
    "    np.save(Xfilename, X)\n",
    "    np.save(yfilename, y)\n",
    "    loaded = True\n",
    "    print(\"X and y saved.\")\n",
    "    print(X.shape)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_save = \"./model/model.pkl\"\n",
    "loaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drange(x, y, jump):\n",
    "    while x < y:\n",
    "        yield float(x)\n",
    "        x += decimal.Decimal(jump)\n",
    "c_vars = list(drange(1, 10, '0.5'))\n",
    "parameters = {'kernel':('linear', 'rbf', 'sigmoid', 'poly'), \n",
    "              'C':c_vars}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector length: 8412\n"
     ]
    }
   ],
   "source": [
    "if (os.path.isfile(model_save) != True):\n",
    "    print('Feature vector length:', len(X_train[0]))\n",
    "    # Use a linear SVC \n",
    "    clf = SVC()\n",
    "    # clf = GridSearchCV(svc, parameters)\n",
    "    # Check the training time for the SVC\n",
    "    t=time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    t2 = time.time()\n",
    "    print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "    # Check the score of the SVC\n",
    "    print('Test Accuracy of SVC = ', round(clf.score(X_test, y_test), 4))\n",
    "    # Check the prediction time for a single sample\n",
    "    t=time.time()\n",
    "    print(\"Prediction took:\", (t-t2), \"seconds\")\n",
    "    joblib.dump(clf, model_save) \n",
    "    print(\"model saved\")\n",
    "else:\n",
    "    print(\"loading from file\")\n",
    "    clf = joblib.load(model_save) \n",
    "    print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "def find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, \n",
    "              spatial_size, hist_bins):\n",
    "    \n",
    "    draw_img = np.copy(img)\n",
    "    img = img.astype(np.float32)/255\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    ctrans_tosearch = convert_color(img_tosearch, conv='RGB2YCrCb')\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), \n",
    "        np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell)-1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell)-1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell)-1 \n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "          \n",
    "            # Get color features\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "            hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "            test_features = X_scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))    \n",
    "            #test_features = X_scaler.transform(np.hstack((shape_feat, hist_feat)).reshape(1, -1))    \n",
    "            test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),\n",
    "                (xbox_left+win_draw,ytop_draw+win_draw+ystart),(0,0,255),6) \n",
    "                \n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ystart = 400\n",
    "ystop = 656\n",
    "scale = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "out_img = find_cars(img, ystart, ystop, scale, clf, X_scaler, orient, pix_per_cell, cell_per_block, \n",
    "                    spatial_size, nbins)\n",
    "\n",
    "plt.imshow(out_img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
