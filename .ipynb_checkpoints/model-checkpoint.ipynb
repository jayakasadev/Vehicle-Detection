{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "from itertools import chain\n",
    "from skimage.feature import hog\n",
    "import time\n",
    "# from os import path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL\n",
    "I'm going to load the training samples with which I will train the classifier. These example images come from a combination of the GTI vehicle image database, the KITTI vision benchmark suite, and examples extracted from the project video itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8792\n",
      "<class 'str'>\n",
      "8968\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "path_to_vehicles = \"./dataset/vehicles/\"\n",
    "path_to_nonvehicles = \"./dataset/non-vehicles/\"\n",
    "\n",
    "\"\"\"\n",
    "This method is for when I want to load all image file paths into memory\n",
    "\"\"\"\n",
    "def file_list(path):\n",
    "    return [y for x in os.walk(path) for y in glob(os.path.join(x[0], '*.png'))]\n",
    "\n",
    "\"\"\"\n",
    "This method is for when I want to get a generator of all image file paths \n",
    "\"\"\"\n",
    "def file_generator(path):\n",
    "    return (chain.from_iterable(glob(os.path.join(x[0], '*.png')) for x in os.walk('.')))\n",
    "\n",
    "vehicles = file_list(path_to_vehicles)\n",
    "non_vehicles = file_list(path_to_nonvehicles)\n",
    "\n",
    "print(len(vehicles))\n",
    "print(type(vehicles[0]))\n",
    "print(len(non_vehicles))\n",
    "print(type(non_vehicles[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters used in the phase of feature extraction\n",
    "feat_extraction_params = {'color_space': 'RGB',       # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "                          'orient': 9,                # HOG orientations\n",
    "                          'pix_per_cell': 8,          # HOG pixels per cell\n",
    "                          'cell_per_block': 2,        # HOG cells per block\n",
    "                          'spatial_size': (32, 32),   # Spatial binning dimensions\n",
    "                          'nbins': 16,            # Number of histogram bins\n",
    "                          'hog_channel': \"ALL\",       # Can be 0, 1, 2, or \"ALL\"\n",
    "                          'spatial_feat': True,       # Spatial features on or off\n",
    "                          'hist_feat': True,          # Histogram features on or off\n",
    "                          'hog_feat': True,           # HOG features on or off\n",
    "                          'feature_vec' : True ,       # Call ravel() automatically or not,\n",
    "                          'transform_sqrt': False,     # Turn \"gamma\" normalization on or off\n",
    "                          'visualize': True}          # Turn on visualization or off "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_color(img, conv='YCrCb'):\n",
    "    if conv == 'YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    if conv == 'RGB':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if conv == 'LUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2LUV)\n",
    "    if conv == 'HSV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    if conv == 'HLS':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    if conv == 'YUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis = False,\n",
    "                     feature_vec = True, transform_sqrt = False):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt = transform_sqrt, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt = transform_sqrt, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    color1 = cv2.resize(img[:,:,0], size).ravel()\n",
    "    color2 = cv2.resize(img[:,:,1], size).ravel()\n",
    "    color3 = cv2.resize(img[:,:,2], size).ravel()\n",
    "    return np.hstack((color1, color2, color3))\n",
    "                        \n",
    "def color_hist(img, nbins=32):    #bins_range=(0, 256)\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "# Consider using multiple threads here to speed this process up\n",
    "def load_features(image):\n",
    "    # loading dictionary values\n",
    "    color_space = feat_extraction_params['color_space']\n",
    "    \n",
    "    orient = feat_extraction_params['orient']\n",
    "    pix_per_cell = feat_extraction_params['pix_per_cell']\n",
    "    cell_per_block = feat_extraction_params['cell_per_block']\n",
    "    spatial_size = feat_extraction_params['spatial_size']\n",
    "    nbins = feat_extraction_params['nbins']\n",
    "    \n",
    "    hog_channel = feat_extraction_params['hog_channel']\n",
    "    \n",
    "    feature_vec = feat_extraction_params['feature_vec']\n",
    "    transform_sqrt = feat_extraction_params['transform_sqrt']\n",
    "    visualize = feat_extraction_params['visualize']\n",
    "    \n",
    "    spatial_feat = feat_extraction_params['spatial_feat']\n",
    "    hist_feat = feat_extraction_params['hist_feat']\n",
    "    hog_feat = feat_extraction_params['hog_feat']\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    img = np.copy(image)\n",
    "    img = convert_color(img, conv = color_space)\n",
    "    \n",
    "    if spatial_feat:\n",
    "        features.append(bin_spatial(img, size = spatial_size))\n",
    "    \n",
    "    if hist_feat:\n",
    "        features.append(color_hist(img, nbins = nbins))\n",
    "    \n",
    "    if hog_feat:\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(img.shape[2]):\n",
    "                hog_features.extend(get_hog_features(img[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=visualize, feature_vec=feature_vec))      \n",
    "        else:\n",
    "            hog_features = get_hog_features(img[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis = visualize, feature_vec = feature_vec, \n",
    "                                            transform_sqrt = transform_sqrt)\n",
    "        \n",
    "        features.append(hog_features)\n",
    "    \n",
    "    return np.concatenate(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_extraction(file_list):\n",
    "    \n",
    "    # features will be stores in a list\n",
    "    features = []\n",
    "    \n",
    "    for file in file_list:\n",
    "        img = cv2.imread(file)\n",
    "        \n",
    "        features.append(load_features(img))\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ab93dba2d7de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# reassigning the vehicles and non_vehicles variable because I no longer need the paths to the images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;31m# better to free that memory up\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvehicles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_extraction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvehicles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnon_vehicles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_extraction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnon_vehicles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-145d9d9bd315>\u001b[0m in \u001b[0;36mfeature_extraction\u001b[0;34m(file_list)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-741c1e0dba5c>\u001b[0m in \u001b[0;36mload_features\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 hog_features.extend(get_hog_features(img[:,:,channel], \n\u001b[1;32m     86\u001b[0m                                     \u001b[0morient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpix_per_cell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell_per_block\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                                     vis=visualize, feature_vec=feature_vec))      \n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             hog_features = get_hog_features(img[:,:,hog_channel], orient, \n",
      "\u001b[0;32m<ipython-input-8-741c1e0dba5c>\u001b[0m in \u001b[0;36mget_hog_features\u001b[0;34m(img, orient, pix_per_cell, cell_per_block, vis, feature_vec, transform_sqrt)\u001b[0m\n\u001b[1;32m     21\u001b[0m                                   \u001b[0mcells_per_block\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell_per_block\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell_per_block\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                                   \u001b[0mtransform_sqrt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform_sqrt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                                   visualise=vis, feature_vector=feature_vec)\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhog_image\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[1;31m# Otherwise call with one output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Tools\\Anaconda3\\lib\\site-packages\\skimage\\feature\\_hog.py\u001b[0m in \u001b[0;36mhog\u001b[0;34m(image, orientations, pixels_per_cell, cells_per_block, visualise, transform_sqrt, feature_vector, normalise)\u001b[0m\n\u001b[1;32m    159\u001b[0m                                        \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcentre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                                        int(centre[1] - dy))\n\u001b[0;32m--> 161\u001b[0;31m                     \u001b[0mhog_image\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0morientation_histogram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# reassigning the vehicles and non_vehicles variable because I no longer need the paths to the images\n",
    "# better to free that memory up\n",
    "vehicles = feature_extraction(vehicles)\n",
    "non_vehicles = feature_extraction(non_vehicles)\n",
    "\n",
    "t1 = time.time()\n",
    "print(vehicles[0].shape)\n",
    "print(non_vehicles[0].shape)\n",
    "t2 = time.time()\n",
    "\n",
    "print(\"This process took\", (t2-t1), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
