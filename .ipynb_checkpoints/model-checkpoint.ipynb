{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from itertools import chain\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import time\n",
    "\n",
    "# from os import path\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"All libraries are loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL\n",
    "I'm going to load the training samples with which I will train the classifier. These example images come from a combination of the GTI vehicle image database, the KITTI vision benchmark suite, and examples extracted from the project video itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_to_vehicles = \"./dataset/vehicles/\"\n",
    "path_to_nonvehicles = \"./dataset/non-vehicles/\"\n",
    "\n",
    "\"\"\"\n",
    "This method is for when I want to load all image file paths into memory\n",
    "\"\"\"\n",
    "def file_list(path):\n",
    "    return [y for x in os.walk(path) for y in glob(os.path.join(x[0], '*.png'))]\n",
    "\n",
    "\"\"\"\n",
    "This method is for when I want to get a generator of all image file paths \n",
    "\"\"\"\n",
    "def file_generator(path):\n",
    "    return (chain.from_iterable(glob(os.path.join(x[0], '*.png')) for x in os.walk('.')))\n",
    "\n",
    "vehicles = file_list(path_to_vehicles)\n",
    "non_vehicles = file_list(path_to_nonvehicles)\n",
    "\n",
    "print(len(vehicles))\n",
    "print(type(vehicles[0]))\n",
    "print(len(non_vehicles))\n",
    "print(type(non_vehicles[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters used in the phase of feature extraction\n",
    "feat_extraction_params = {'color_space': 'RGB',       # Can be RGB, HSV, LUV, HLS, YUV, YCrCb, BGR\n",
    "                          'orient': 9,                # HOG orientations\n",
    "                          'pix_per_cell': 8,          # HOG pixels per cell\n",
    "                          'cell_per_block': 2,        # HOG cells per block\n",
    "                          'spatial_size': (32, 32),   # Spatial binning dimensions\n",
    "                          'nbins': 16,            # Number of histogram bins\n",
    "                          'hog_channel': \"ALL\",       # Can be 0, 1, 2, or \"ALL\"\n",
    "                          'spatial_feat': True,       # Spatial features on or off\n",
    "                          'hist_feat': True,          # Histogram features on or off\n",
    "                          'hog_feat': True,           # HOG features on or off\n",
    "                          'feature_vec' : True ,       # Call ravel() automatically or not,\n",
    "                          'transform_sqrt': False,     # Turn \"gamma\" normalization on or off\n",
    "                          'visualize': False}          # Turn on visualization or off "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_color(img, conv='YCrCb'):\n",
    "    if conv == 'YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    if conv == 'RGB':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if conv == 'LUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2LUV)\n",
    "    if conv == 'HSV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    if conv == 'HLS':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    if conv == 'YUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2YUV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True, transform_sqrt = False):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=transform_sqrt, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt=transform_sqrt, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_spatial(img, size=(32, 32)):\n",
    "    color1 = cv2.resize(img[:,:,0], size).ravel()\n",
    "    color2 = cv2.resize(img[:,:,1], size).ravel()\n",
    "    color3 = cv2.resize(img[:,:,2], size).ravel()\n",
    "    return np.hstack((color1, color2, color3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color_hist(img, nbins=32):    #bins_range=(0, 256)\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Consider using multiple threads here to speed this process up\n",
    "def load_features(image):\n",
    "    # loading dictionary values\n",
    "    color_space = feat_extraction_params['color_space']\n",
    "    \n",
    "    orient = feat_extraction_params['orient']\n",
    "    pix_per_cell = feat_extraction_params['pix_per_cell']\n",
    "    cell_per_block = feat_extraction_params['cell_per_block']\n",
    "    spatial_size = feat_extraction_params['spatial_size']\n",
    "    nbins = feat_extraction_params['nbins']\n",
    "    \n",
    "    hog_channel = feat_extraction_params['hog_channel']\n",
    "    \n",
    "    feature_vec = feat_extraction_params['feature_vec']\n",
    "    transform_sqrt = feat_extraction_params['transform_sqrt']\n",
    "    visualize = feat_extraction_params['visualize']\n",
    "    \n",
    "    spatial_feat = feat_extraction_params['spatial_feat']\n",
    "    hist_feat = feat_extraction_params['hist_feat']\n",
    "    hog_feat = feat_extraction_params['hog_feat']\n",
    "    \n",
    "    \n",
    "    #1) Define an empty list to receive features\n",
    "    features = []\n",
    "    \n",
    "    #2) Apply color conversion if other than 'RGB'\n",
    "    if color_space != 'BGR':\n",
    "        img = convert_color(image, conv=color_space)\n",
    "    else: \n",
    "        feature_image = np.copy(img)      \n",
    "    \n",
    "    #3) Compute spatial features if flag is set\n",
    "    if spatial_feat == True:\n",
    "        spatial_features = bin_spatial(img, size=spatial_size)\n",
    "        \n",
    "        #4) Append features to list\n",
    "        features.append(spatial_features)\n",
    "    \n",
    "    #5) Compute histogram features if flag is set\n",
    "    if hist_feat == True:\n",
    "        hist_features = color_hist(img, nbins=nbins)\n",
    "        \n",
    "        #6) Append features to list\n",
    "        features.append(hist_features)\n",
    "    \n",
    "    #7) Compute HOG features if flag is set\n",
    "    if hog_feat == True:\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(img.shape[2]):\n",
    "                hog_features.extend(get_hog_features(img[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))      \n",
    "        else:\n",
    "            hog_features = get_hog_features(img[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        #8) Append features to list\n",
    "        features.append(hog_features)\n",
    "\n",
    "    #9) Return concatenated array of features\n",
    "    return np.concatenate(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_extraction(file_list):\n",
    "    \n",
    "    # features will be stores in a list\n",
    "    features = []\n",
    "    \n",
    "    for file in file_list:\n",
    "        # print(file)\n",
    "        img = cv2.imread(file)\n",
    "        \n",
    "        features.append(load_features(img))\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xfilename = \"./variables/X_values.txt\"\n",
    "yfilename = \"./variables/y_values.txt\"\n",
    "loaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if ((os.path.isfile(Xfilename) != True) and (os.path.isfile(yfilename) != True)): \n",
    "    # reassigning the vehicles and non_vehicles variable because I no longer need the paths to the images\n",
    "    # better to free that memory up\n",
    "    t1 = time.time()\n",
    "    vehicles = feature_extraction(vehicles)\n",
    "    t2 = time.time()\n",
    "    print(\"Vehicles processing took\", (t2-t1), \"seconds.\")\n",
    "    t3 = time.time()\n",
    "    non_vehicles = feature_extraction(non_vehicles)\n",
    "    t4 = time.time()\n",
    "    print(\"Non-Vehicles processing took\", (t4-t3), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(type(vehicles))\n",
    "print(len(vehicles))\n",
    "print(type(non_vehicles))\n",
    "print(type(vehicles[0]))\n",
    "print(type(non_vehicles[0]))\n",
    "print(vehicles[0].shape)\n",
    "print(non_vehicles[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(non_vehicles[0][0])\n",
    "print(type(non_vehicles[0][0]))\n",
    "\n",
    "\"\"\"\n",
    "def convertToFloat(src):\n",
    "    dst = []\n",
    "    for elem in src:\n",
    "        print(type(elem))\n",
    "        print(elem.shape)\n",
    "        x = np.array(list(elem[:]), dtype=np.float64)\n",
    "        dst.append(x)\n",
    "    return dst\n",
    "\n",
    "vehicles = convertToFloat(vehicles)\n",
    "non_vehicles = convertToFloat(non_vehicles)\n",
    "\n",
    "print(non_vehicles[0][0])\n",
    "print(type(non_vehicles[0][0]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if ((os.path.isfile(Xfilename) != True) and (os.path.isfile(yfilename) != True)):\n",
    "    tup = (vehicles, non_vehicles)\n",
    "    X = np.vstack(tup)\n",
    "    # X = np.array(X, dtype = np.float64)                        \n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    # Apply the scaler to X\n",
    "    X = X_scaler.transform(X)\n",
    "\n",
    "    # Define the labels vector\n",
    "    y = np.hstack((np.ones(len(vehicles)), np.zeros(len(non_vehicles))))\n",
    "\n",
    "\n",
    "    print(vehicles[0].shape)\n",
    "    print(non_vehicles[0].shape)\n",
    "else:\n",
    "    X = np.loadtxt(Xfilename, dtype='int', delimiter=' ')\n",
    "    y = np.loadtxt(yfilename, dtype='int', delimiter=' ')\n",
    "    loaded = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if !loaded:\n",
    "    np.savetxt(Xfilename, X, delimiter=\" \", fmt=\"%d\")\n",
    "    np.savetxt(yfilename, y, delimiter=\" \", fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "print('Using:',orient, 'orientations', pix_per_cell, 'pixels per cell and', cell_per_block, 'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
